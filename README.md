# üêæ Cat vs Dog AI - Deep Learning Image Classifier

> **A production-ready deep learning application that classifies images as cats or dogs with ~92% accuracy.**  
> Choose between a beautiful **Streamlit web app** for end-users or a powerful **FastAPI REST API** for seamless integration with any application.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.20+-orange.svg)](https://www.tensorflow.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## üìñ Table of Contents

- [‚ú® Features](#-features)
- [üé¨ Demo](#-demo)
- [üöÄ Quick Start](#-quick-start)
  - [Prerequisites](#prerequisites)
  - [Clone & Setup](#-clone-the-repository)
  - [Web Application (Streamlit)](#1Ô∏è‚É£-web-application-streamlit)
  - [REST API (FastAPI)](#2Ô∏è‚É£-rest-api-fastapi)
  - [Docker Deployment](#3Ô∏è‚É£-docker-deployment-recommended)
- [üì° API Documentation](#-api-documentation)
  - [Available Endpoints](#available-endpoints)
  - [Response Format](#response-format)
  - [Error Handling](#error-handling)
- [üí° Usage Examples](#-usage-examples)
  - [Python Integration](#python-requests)
  - [JavaScript/React](#javascript-fetch-api)
  - [Mobile Apps](#mobile-flutterdart)
  - [cURL Commands](#curl)
- [üèóÔ∏è Model Architecture](#Ô∏è-model-architecture)
- [üîÑ Project Workflow](#-project-workflow)
- [üìÅ Project Structure](#-project-structure)
- [üîß Technologies & Deployment](#-technologies-used)
- [üêõ Troubleshooting](#-troubleshooting)
- [ü§ù Contributing](#-contributing)
- [üìù License](#-license)
- [üìß Contact](#-contact)

---

## ‚ú® Features

### üéØ **Two Powerful Interfaces - Choose What Fits Your Needs**

| Feature                      | Web App (Streamlit)       | REST API (FastAPI)                    |
| ---------------------------- | ------------------------- | ------------------------------------- |
| **User Interface**           | ‚úÖ Interactive web UI     | ‚ùå API only (integrate with your app) |
| **Real-time Classification** | ‚úÖ Instant visual results | ‚úÖ JSON response                      |
| **Batch Processing**         | ‚ùå One image at a time    | ‚úÖ Up to 10 images per request        |
| **Integration**              | ‚ùå Standalone app         | ‚úÖ Any language/platform              |
| **Auto Documentation**       | ‚ùå N/A                    | ‚úÖ Swagger UI + ReDoc                 |
| **Mobile Friendly**          | ‚úÖ Responsive design      | ‚úÖ Mobile apps can integrate          |
| **Docker Support**           | ‚úÖ Available              | ‚úÖ Production-ready                   |
| **Best For**                 | End-users, demos          | Developers, production systems        |

### üé® **Web Application Highlights**

- üñºÔ∏è **Modern UI** with gradient animations and smooth transitions
- üéØ **Drag-and-drop** image upload with instant preview
- üìä **Confidence meters** with visual progress bars
- üì± **Mobile responsive** design that works everywhere
- ‚ö° **Auto model download** from Google Drive (111 MB, cached locally)
- üöÄ **Fast inference** ~100-300ms per image
- üé® **Animated result cards** color-coded by prediction (orange for cats, blue for dogs)
- üìà **Detailed metrics** expandable technical information

### üîå **REST API Highlights**

- üåê **RESTful endpoints** following industry best practices
- üì¶ **Batch prediction** process up to 10 images in one request
- üîì **CORS enabled** ready for web and mobile apps
- ‚úÖ **Input validation** file type, size, and format checks
- üíö **Health checks** monitor API and model status
- üõ°Ô∏è **Production-ready** with comprehensive logging and error handling
- üìö **Interactive docs** Swagger UI at `/docs` and ReDoc at `/redoc`
- ‚ö° **Async support** high-performance with uvicorn/gunicorn
- üê≥ **Docker ready** containerized for easy deployment
- üìä **Detailed responses** confidence scores, probabilities, and metadata

---

## üé¨ Demo

### Web Application

![Streamlit Demo](https://via.placeholder.com/800x400?text=Streamlit+Web+App+Demo)

### API Response Example

```json
{
  "prediction": "Cat",
  "confidence_percentage": 92.15,
  "probabilities": {
    "cat": 92.15,
    "dog": 7.85
  }
}
```

---

## üöÄ Quick Start

### Prerequisites

Before you begin, ensure you have:

- ‚úÖ **Python 3.8 or higher** installed ([Download Python](https://www.python.org/downloads/))
- ‚úÖ **pip** package manager (comes with Python)
- ‚úÖ **Internet connection** (required for first-time model download - 111 MB)
- ‚úÖ **Git** for cloning the repository ([Download Git](https://git-scm.com/downloads))
- üì¶ **Optional**: Docker Desktop for containerized deployment

### üì• Clone the Repository

```bash
git clone https://github.com/fsRakib/Image-Classification-CNN.git
cd Image-Classification-CNN
```

### üîß Create Virtual Environment (Recommended)

Creating a virtual environment keeps dependencies isolated and prevents conflicts with other projects.

**Windows (PowerShell):**

```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
```

**Linux/Mac:**

```bash
python -m venv venv
source venv/bin/activate
```

**You should see `(venv)` in your terminal prompt after activation.**

---

## 1Ô∏è‚É£ Web Application (Streamlit)

**Perfect for:** End-users, demos, quick testing, and visual presentations

### Install Dependencies

```bash
pip install -r requirements.txt
```

**This installs:**

- `streamlit` - Web application framework
- `tensorflow` - Deep learning framework
- `pillow` - Image processing
- `numpy` - Numerical operations
- `gdown` - Google Drive downloader

### Run the Application

```bash
streamlit run streamlit_app.py
```

**You'll see output like:**

```
You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://192.168.1.100:8501
```

### How to Use the Web App

1. üåê **Open your browser** to `http://localhost:8501`
2. üì§ **Upload an image** (JPG, JPEG, or PNG) using the file uploader
3. ‚è±Ô∏è **Wait for analysis** (~100-300ms)
4. üìä **View results** with:
   - Prediction label (Cat üê± or Dog üêï)
   - Confidence percentage with visual meter
   - Animated result card (orange for cat, blue for dog)
   - Expandable technical details

**Visual Flow:**

```
Upload Image ‚Üí Auto Preprocess ‚Üí CNN Prediction ‚Üí Beautiful Results
   üñºÔ∏è              ‚öôÔ∏è                 üß†               ‚ú®
```

### Features You'll Love

- **Instant feedback** - No page reloads needed
- **Clear visualizations** - Confidence bars and probability charts
- **Detailed metadata** - Image size, mode, processing info
- **Error handling** - Helpful messages if something goes wrong
- **Model auto-download** - First run downloads model automatically

---

## 2Ô∏è‚É£ REST API (FastAPI)

**Perfect for:** Developers, production systems, mobile apps, integration with existing applications

### Install Dependencies

```bash
pip install -r requirements-api.txt
```

**This installs:**

- `fastapi` - Modern web framework for APIs
- `uvicorn` - Lightning-fast ASGI server
- `python-multipart` - File upload support
- `tensorflow` - Deep learning framework
- `pillow` - Image processing
- `numpy` - Numerical operations
- `gdown` - Google Drive downloader

### Run the API Server

**Option 1: Direct Python execution**

```bash
python api.py
```

**Option 2: Using uvicorn (recommended for development)**

```bash
uvicorn api:app --host 0.0.0.0 --port 8000 --reload
```

The `--reload` flag enables auto-restart on code changes.

**Option 3: Using helper scripts**

```powershell
# Windows PowerShell
.\start_api.ps1

# Linux/Mac
chmod +x start_api.sh
./start_api.sh
```

**Option 4: Production deployment with Gunicorn**

```bash
pip install gunicorn
gunicorn api:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

### Access the API

Once running, you can access:

- üåê **API Base URL:** http://localhost:8000
- üìö **Interactive Swagger Docs:** http://localhost:8000/docs
- üìñ **ReDoc Documentation:** http://localhost:8000/redoc
- üíö **Health Check:** http://localhost:8000/health

### Quick Test the API

**Using the test script:**

```bash
python test_api_quick.py
```

**Using cURL:**

```bash
curl -X POST "http://localhost:8000/predict" -F "file=@cat.jpg"
```

**Using Python:**

```python
import requests

with open("cat.jpg", "rb") as f:
    response = requests.post("http://localhost:8000/predict", files={"file": f})
    result = response.json()
    print(f"{result['prediction']} - {result['confidence_percentage']}%")
```

**Expected Response:**

```json
{
  "success": true,
  "filename": "cat.jpg",
  "prediction": "Cat",
  "confidence_percentage": 92.15,
  "probabilities": {
    "cat": 92.15,
    "dog": 7.85
  }
}
```

---

## 3Ô∏è‚É£ Docker Deployment (Recommended)

**Perfect for:** Production environments, cloud deployments, ensuring consistency across different platforms

### Why Docker?

‚úÖ **"Works Everywhere"** - Same environment on Windows, Linux, Mac, and Cloud  
‚úÖ **No Dependency Hell** - All packages pre-installed in container  
‚úÖ **Isolated Environment** - No conflicts with other projects  
‚úÖ **Easy Scaling** - Deploy multiple instances instantly  
‚úÖ **Cloud-Ready** - Deploy to AWS, GCP, Azure, Heroku in minutes  
‚úÖ **Version Control** - Container images are versioned and reproducible

### Prerequisites for Docker

- Install [Docker Desktop](https://www.docker.com/products/docker-desktop) for Windows/Mac
- Or install Docker Engine on Linux

### Build and Run with Docker Compose (Easiest)

```bash
# Build and start the API
docker-compose up --build

# Run in background (detached mode)
docker-compose up -d

# View logs
docker-compose logs -f

# Stop the container
docker-compose down
```

### Build and Run with Docker Directly

```bash
# Build the image
docker build -t cat-dog-api .

# Run the container
docker run -p 8000:8000 cat-dog-api

# Run in background with volume mounting
docker run -d -p 8000:8000 -v ${PWD}:/app --name catdog cat-dog-api

# View logs
docker logs -f catdog

# Stop container
docker stop catdog
```

### Access Dockerized API

- üåê **API:** http://localhost:8000
- üìö **Docs:** http://localhost:8000/docs
- üíö **Health:** http://localhost:8000/health

### Docker Benefits Comparison

| Aspect          | Without Docker                     | With Docker                            |
| --------------- | ---------------------------------- | -------------------------------------- |
| **Setup Time**  | 30-60 min (install dependencies)   | 2-5 min (just run `docker-compose up`) |
| **Consistency** | "Works on my machine" syndrome     | ‚úÖ Works identically everywhere        |
| **Deployment**  | Manual setup on each server        | Single command deployment              |
| **Scaling**     | Configure each instance manually   | Auto-scaling ready with orchestration  |
| **Updates**     | Update dependencies on each server | Build new image, deploy everywhere     |
| **Rollback**    | Difficult, manual process          | Switch to previous container version   |

### Production Deployment Options

The Docker image can be deployed to:

- **AWS ECS/EKS** - Elastic Container Service or Kubernetes
- **Google Cloud Run** - Serverless container platform
- **Azure Container Instances** - Simple container hosting
- **DigitalOcean App Platform** - Managed container deployment
- **Heroku** - Container registry deployment
- **Railway** - Modern platform-as-a-service
- **Render** - Free tier available for testing

---

## ÔøΩ API Documentation

### Available Endpoints

The FastAPI server provides five main endpoints for different operations:

| Endpoint         | Method | Description                             | Auth Required |
| ---------------- | ------ | --------------------------------------- | ------------- |
| `/`              | GET    | API information and available endpoints | No            |
| `/health`        | GET    | Health check and model status           | No            |
| `/model/info`    | GET    | Detailed model information              | No            |
| `/predict`       | POST   | Single image prediction                 | No            |
| `/predict/batch` | POST   | Batch predictions (up to 10 images)     | No            |

### 1. Root Endpoint - API Information

Get basic API information and discover available endpoints.

**Request:**

```http
GET /
```

**Response:**

```json
{
  "message": "Cat vs Dog Classifier API",
  "version": "1.0.0",
  "status": "active",
  "description": "Deep learning API for classifying images as cats or dogs",
  "endpoints": {
    "predict": "/predict (POST)",
    "batch_predict": "/predict/batch (POST)",
    "health": "/health (GET)",
    "model_info": "/model/info (GET)",
    "docs": "/docs (Interactive Swagger UI)",
    "redoc": "/redoc (ReDoc Documentation)"
  },
  "model": {
    "type": "CNN",
    "accuracy": "~92%",
    "input_size": "128x128 RGB"
  }
}
```

### 2. Health Check

Monitor API and model status - essential for production deployments.

**Request:**

```http
GET /health
```

**Response:**

```json
{
  "status": "healthy",
  "model_loaded": true,
  "model_path": "dogs_vs_cats_production_model.keras",
  "model_exists": true,
  "timestamp": "2024-01-15T10:30:00Z"
}
```

**Use Cases:**

- Load balancer health checks
- Monitoring and alerting
- Kubernetes liveness/readiness probes
- Service mesh integration

### 3. Model Information

Get detailed information about the loaded model.

**Request:**

```http
GET /model/info
```

**Response:**

```json
{
  "model_name": "Dogs vs Cats CNN Classifier",
  "model_type": "Convolutional Neural Network",
  "input_shape": [128, 128, 3],
  "output_classes": ["Cat", "Dog"],
  "model_size_mb": 111.24,
  "framework": "TensorFlow/Keras",
  "training_accuracy": "~92%",
  "supported_formats": ["jpg", "jpeg", "png"],
  "max_file_size_mb": 10,
  "preprocessing": {
    "resize": "128x128",
    "normalization": "0-1 range",
    "color_mode": "RGB"
  }
}
```

### 4. Single Image Prediction

Classify a single image and get detailed results.

**Request:**

```http
POST /predict
Content-Type: multipart/form-data

file: <image file>
```

**cURL Example:**

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "accept: application/json" \
  -F "file=@cat_image.jpg"
```

**Python Example:**

```python
import requests

with open("cat.jpg", "rb") as f:
    response = requests.post(
        "http://localhost:8000/predict",
        files={"file": f}
    )
    print(response.json())
```

**Response:**

```json
{
  "success": true,
  "filename": "cat_image.jpg",
  "prediction": "Cat",
  "confidence_percentage": 87.34,
  "raw_score": 0.1266,
  "probabilities": {
    "cat": 87.34,
    "dog": 12.66
  },
  "metadata": {
    "image_size": [800, 600],
    "image_mode": "RGB",
    "model_input_size": [128, 128],
    "file_size_kb": 245.3,
    "processing_time_ms": 156
  }
}
```

**Response Fields Explained:**

- `success` - Boolean indicating if prediction was successful
- `filename` - Original filename of uploaded image
- `prediction` - Classification result ("Cat" or "Dog")
- `confidence_percentage` - Confidence level (0-100%)
- `raw_score` - Raw model output (0.0-1.0, where >0.5 = Dog)
- `probabilities` - Percentage breakdown for both classes
- `metadata` - Additional information about image and processing

### 5. Batch Prediction

Process multiple images in a single request (maximum 10 images).

**Request:**

```http
POST /predict/batch
Content-Type: multipart/form-data

files: <image file 1>
files: <image file 2>
files: <image file 3>
```

**cURL Example:**

```bash
curl -X POST "http://localhost:8000/predict/batch" \
  -F "files=@cat1.jpg" \
  -F "files=@dog1.jpg" \
  -F "files=@cat2.jpg"
```

**Python Example:**

```python
import requests

files = [
    ("files", open("cat1.jpg", "rb")),
    ("files", open("dog1.jpg", "rb")),
    ("files", open("cat2.jpg", "rb"))
]

response = requests.post(
    "http://localhost:8000/predict/batch",
    files=files
)
print(response.json())
```

**Response:**

```json
{
  "success": true,
  "total_images": 3,
  "successful_predictions": 3,
  "failed_predictions": 0,
  "processing_time_ms": 421,
  "results": [
    {
      "filename": "cat1.jpg",
      "success": true,
      "prediction": "Cat",
      "confidence_percentage": 92.15,
      "probabilities": {
        "cat": 92.15,
        "dog": 7.85
      }
    },
    {
      "filename": "dog1.jpg",
      "success": true,
      "prediction": "Dog",
      "confidence_percentage": 88.42,
      "probabilities": {
        "cat": 11.58,
        "dog": 88.42
      }
    },
    {
      "filename": "cat2.jpg",
      "success": true,
      "prediction": "Cat",
      "confidence_percentage": 95.67,
      "probabilities": {
        "cat": 95.67,
        "dog": 4.33
      }
    }
  ]
}
```

### Response Format

All successful responses follow this structure:

```json
{
  "success": true,
  "data": {
    /* endpoint-specific data */
  }
}
```

### Error Handling

The API returns standard HTTP status codes and descriptive error messages.

#### Common Error Codes

| Status Code | Meaning             | Typical Causes                              |
| ----------- | ------------------- | ------------------------------------------- |
| 200         | Success             | Request processed successfully              |
| 400         | Bad Request         | Invalid file type, missing file, size limit |
| 413         | Payload Too Large   | File exceeds 10MB limit                     |
| 500         | Internal Error      | Model loading failed, prediction error      |
| 503         | Service Unavailable | Model not loaded yet                        |

#### Error Response Format

**400 Bad Request - Invalid File Type:**

```json
{
  "detail": "Invalid file type. Allowed types: jpg, jpeg, png"
}
```

**400 Bad Request - No File Provided:**

```json
{
  "detail": "No file uploaded"
}
```

**413 Payload Too Large:**

```json
{
  "detail": "File too large. Maximum size: 10MB"
}
```

**500 Internal Server Error:**

```json
{
  "detail": "Prediction failed: [specific error message]"
}
```

**503 Service Unavailable:**

```json
{
  "detail": "Model not loaded. Please check server logs."
}
```

### Rate Limiting & Best Practices

**Recommendations for Production:**

1. **Implement Rate Limiting** - Prevent abuse and ensure fair usage
2. **Add Authentication** - Use API keys or JWT tokens
3. **Enable HTTPS** - Secure data transmission
4. **Configure CORS** - Restrict allowed origins
5. **Monitor Performance** - Track response times and errors
6. **Set Up Logging** - Log all requests for debugging and analytics

**Example Rate Limiting Configuration (using slowapi):**

```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

@app.post("/predict")
@limiter.limit("100/hour")  # 100 requests per hour
async def predict_image(request: Request, file: UploadFile):
    # ... prediction logic
```

### Interactive API Documentation

FastAPI automatically generates interactive documentation:

**Swagger UI** (`/docs`):

- Try out endpoints directly in browser
- See request/response schemas
- Test with your own images
- View all available operations

**ReDoc** (`/redoc`):

- Clean, readable documentation
- Better for reference and sharing
- Printable format
- Detailed schema descriptions

### CORS Configuration

The API is configured to allow cross-origin requests from all origins (`*`). For production, restrict this:

```python
# In api.py, modify the CORS middleware:
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://yourdomain.com",
        "https://app.yourdomain.com",
        "http://localhost:3000"  # For local development
    ],
    allow_credentials=True,
    allow_methods=["GET", "POST"],
    allow_headers=["*"],
)
```

---

## üí° Usage Examples

Integrate the Cat vs Dog Classifier API into your applications with these examples across different languages and platforms.

### Python (requests)

The most straightforward way to use the API in Python applications.

```python
import requests
import json

# Base URL
API_URL = "http://localhost:8000"

# 1. Health Check
def check_health():
    response = requests.get(f"{API_URL}/health")
    print("Health Status:", response.json())

# 2. Get Model Info
def get_model_info():
    response = requests.get(f"{API_URL}/model/info")
    info = response.json()
    print(f"Model: {info['model_name']}")
    print(f"Accuracy: {info['training_accuracy']}")

# 3. Single Image Prediction
def predict_single(image_path):
    with open(image_path, "rb") as f:
        files = {"file": f}
        response = requests.post(f"{API_URL}/predict", files=files)

    result = response.json()
    if result["success"]:
        print(f"Prediction: {result['prediction']}")
        print(f"Confidence: {result['confidence_percentage']}%")
        print(f"Probabilities: {result['probabilities']}")
    else:
        print(f"Error: {result.get('detail', 'Unknown error')}")

# 4. Batch Prediction
def predict_batch(image_paths):
    files = [("files", open(path, "rb")) for path in image_paths]
    response = requests.post(f"{API_URL}/predict/batch", files=files)

    result = response.json()
    print(f"Processed {result['total_images']} images:")
    for item in result["results"]:
        print(f"  {item['filename']}: {item['prediction']} ({item['confidence_percentage']}%)")

    # Close all files
    for _, file in files:
        file.close()

# Usage
if __name__ == "__main__":
    check_health()
    get_model_info()
    predict_single("cat.jpg")
    predict_batch(["cat1.jpg", "dog1.jpg", "cat2.jpg"])
```

### JavaScript (Fetch API)

For web applications and Node.js backends.

```javascript
// Configuration
const API_URL = "http://localhost:8000";

// 1. Health Check
async function checkHealth() {
  const response = await fetch(`${API_URL}/health`);
  const data = await response.json();
  console.log("Health:", data);
}

// 2. Single Image Prediction
async function predictImage(fileInput) {
  const formData = new FormData();
  formData.append("file", fileInput.files[0]);

  const response = await fetch(`${API_URL}/predict`, {
    method: "POST",
    body: formData,
  });

  const result = await response.json();

  if (result.success) {
    console.log(`${result.prediction} - ${result.confidence_percentage}%`);
    return result;
  } else {
    throw new Error(result.detail);
  }
}

// 3. Batch Prediction
async function predictBatch(fileList) {
  const formData = new FormData();

  for (let file of fileList) {
    formData.append("files", file);
  }

  const response = await fetch(`${API_URL}/predict/batch`, {
    method: "POST",
    body: formData,
  });

  const result = await response.json();
  return result.results;
}

// 4. With Error Handling
async function safePredictImage(file) {
  try {
    const formData = new FormData();
    formData.append("file", file);

    const response = await fetch(`${API_URL}/predict`, {
      method: "POST",
      body: formData,
    });

    if (!response.ok) {
      const error = await response.json();
      throw new Error(error.detail || "Prediction failed");
    }

    return await response.json();
  } catch (error) {
    console.error("Error:", error.message);
    return null;
  }
}
```

### React Component

Complete React component with file upload and results display.

```jsx
import { useState } from "react";

function CatDogClassifier() {
  const [selectedFile, setSelectedFile] = useState(null);
  const [preview, setPreview] = useState(null);
  const [result, setResult] = useState(null);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState(null);

  const API_URL = "http://localhost:8000";

  const handleFileSelect = (event) => {
    const file = event.target.files[0];
    if (file) {
      setSelectedFile(file);
      setPreview(URL.createObjectURL(file));
      setResult(null);
      setError(null);
    }
  };

  const handlePredict = async () => {
    if (!selectedFile) return;

    setLoading(true);
    setError(null);

    try {
      const formData = new FormData();
      formData.append("file", selectedFile);

      const response = await fetch(`${API_URL}/predict`, {
        method: "POST",
        body: formData,
      });

      if (!response.ok) {
        const error = await response.json();
        throw new Error(error.detail || "Prediction failed");
      }

      const data = await response.json();
      setResult(data);
    } catch (err) {
      setError(err.message);
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="classifier-container">
      <h1>üê±üêï Cat vs Dog Classifier</h1>

      {/* File Upload */}
      <div className="upload-section">
        <input
          type="file"
          accept="image/jpeg,image/jpg,image/png"
          onChange={handleFileSelect}
        />
        <button onClick={handlePredict} disabled={!selectedFile || loading}>
          {loading ? "Analyzing..." : "Classify Image"}
        </button>
      </div>

      {/* Preview */}
      {preview && (
        <div className="preview">
          <img src={preview} alt="Preview" style={{ maxWidth: "400px" }} />
        </div>
      )}

      {/* Loading */}
      {loading && <div className="loading">üîÑ Analyzing image...</div>}

      {/* Error */}
      {error && <div className="error">‚ùå Error: {error}</div>}

      {/* Results */}
      {result && result.success && (
        <div className={`result ${result.prediction.toLowerCase()}`}>
          <h2>
            {result.prediction === "Cat" ? "üê±" : "üêï"} {result.prediction}!
          </h2>
          <div className="confidence">
            <div className="confidence-bar">
              <div
                className="confidence-fill"
                style={{ width: `${result.confidence_percentage}%` }}
              />
            </div>
            <p>Confidence: {result.confidence_percentage}%</p>
          </div>
          <div className="probabilities">
            <p>üê± Cat: {result.probabilities.cat}%</p>
            <p>üêï Dog: {result.probabilities.dog}%</p>
          </div>
        </div>
      )}
    </div>
  );
}

export default CatDogClassifier;
```

### cURL

Command-line examples for testing and automation.

```bash
# Health Check
curl http://localhost:8000/health

# Model Information
curl http://localhost:8000/model/info

# Single Prediction
curl -X POST "http://localhost:8000/predict" \
  -H "accept: application/json" \
  -F "file=@cat_image.jpg"

# Batch Prediction
curl -X POST "http://localhost:8000/predict/batch" \
  -F "files=@cat1.jpg" \
  -F "files=@dog1.jpg" \
  -F "files=@cat2.jpg"

# Save Response to File
curl -X POST "http://localhost:8000/predict" \
  -F "file=@image.jpg" \
  -o result.json

# Pretty Print JSON Response (with jq)
curl -X POST "http://localhost:8000/predict" \
  -F "file=@image.jpg" | jq '.'
```

### Mobile (Flutter/Dart)

For Flutter mobile applications on iOS and Android.

```dart
import 'package:http/http.dart' as http;
import 'dart:convert';
import 'dart:io';

class CatDogClassifierService {
  static const String baseUrl = 'http://localhost:8000';

  // Single Image Prediction
  Future<Map<String, dynamic>> predictImage(File imageFile) async {
    try {
      var request = http.MultipartRequest(
        'POST',
        Uri.parse('$baseUrl/predict'),
      );

      // Add file
      request.files.add(
        await http.MultipartFile.fromPath('file', imageFile.path)
      );

      // Send request
      var streamedResponse = await request.send();
      var response = await http.Response.fromStream(streamedResponse);

      if (response.statusCode == 200) {
        return json.decode(response.body);
      } else {
        throw Exception('Prediction failed: ${response.body}');
      }
    } catch (e) {
      throw Exception('Error: $e');
    }
  }

  // Batch Prediction
  Future<Map<String, dynamic>> predictBatch(List<File> imageFiles) async {
    var request = http.MultipartRequest(
      'POST',
      Uri.parse('$baseUrl/predict/batch'),
    );

    for (var file in imageFiles) {
      request.files.add(
        await http.MultipartFile.fromPath('files', file.path)
      );
    }

    var streamedResponse = await request.send();
    var response = await http.Response.fromStream(streamedResponse);

    return json.decode(response.body);
  }

  // Health Check
  Future<bool> checkHealth() async {
    try {
      var response = await http.get(Uri.parse('$baseUrl/health'));
      var data = json.decode(response.body);
      return data['status'] == 'healthy';
    } catch (e) {
      return false;
    }
  }
}

// Usage Example
void main() async {
  final service = CatDogClassifierService();

  // Check if API is healthy
  bool isHealthy = await service.checkHealth();
  print('API Health: $isHealthy');

  // Predict single image
  File image = File('/path/to/cat.jpg');
  var result = await service.predictImage(image);
  print('Prediction: ${result['prediction']}');
  print('Confidence: ${result['confidence_percentage']}%');
}
```

### Android (Kotlin + Retrofit)

For native Android applications.

```kotlin
import retrofit2.Retrofit
import retrofit2.converter.gson.GsonConverterFactory
import retrofit2.http.*
import okhttp3.MultipartBody
import okhttp3.RequestBody
import java.io.File

// Data Models
data class PredictionResponse(
    val success: Boolean,
    val filename: String,
    val prediction: String,
    val confidence_percentage: Double,
    val probabilities: Probabilities
)

data class Probabilities(
    val cat: Double,
    val dog: Double
)

data class HealthResponse(
    val status: String,
    val model_loaded: Boolean
)

// API Interface
interface CatDogApi {
    @Multipart
    @POST("predict")
    suspend fun predictImage(
        @Part file: MultipartBody.Part
    ): PredictionResponse

    @Multipart
    @POST("predict/batch")
    suspend fun predictBatch(
        @Part files: List<MultipartBody.Part>
    ): BatchPredictionResponse

    @GET("health")
    suspend fun checkHealth(): HealthResponse
}

// Retrofit Setup
object ApiClient {
    private const val BASE_URL = "http://localhost:8000/"

    val api: CatDogApi by lazy {
        Retrofit.Builder()
            .baseUrl(BASE_URL)
            .addConverterFactory(GsonConverterFactory.create())
            .build()
            .create(CatDogApi::class.java)
    }
}

// Usage in ViewModel or Repository
class CatDogRepository {
    private val api = ApiClient.api

    suspend fun classifyImage(file: File): PredictionResponse {
        val requestFile = file.asRequestBody("image/jpeg".toMediaTypeOrNull())
        val body = MultipartBody.Part.createFormData("file", file.name, requestFile)
        return api.predictImage(body)
    }

    suspend fun checkApiHealth(): Boolean {
        return try {
            val response = api.checkHealth()
            response.status == "healthy"
        } catch (e: Exception) {
            false
        }
    }
}

// Usage in Activity/Fragment
lifecycleScope.launch {
    try {
        val file = File("/path/to/image.jpg")
        val result = repository.classifyImage(file)

        // Update UI
        binding.predictionText.text = result.prediction
        binding.confidenceText.text = "${result.confidence_percentage}%"

    } catch (e: Exception) {
        // Handle error
        Toast.makeText(context, "Error: ${e.message}", Toast.LENGTH_LONG).show()
    }
}
```

### iOS (Swift + Alamofire)

For native iOS applications.

```swift
import Alamofire
import UIKit

// Response Models
struct PredictionResponse: Codable {
    let success: Bool
    let filename: String
    let prediction: String
    let confidence_percentage: Double
    let probabilities: Probabilities
}

struct Probabilities: Codable {
    let cat: Double
    let dog: Double
}

struct HealthResponse: Codable {
    let status: String
    let model_loaded: Bool
}

// API Service
class CatDogAPIService {
    static let shared = CatDogAPIService()
    private let baseURL = "http://localhost:8000"

    // Single Image Prediction
    func predictImage(image: UIImage, completion: @escaping (Result<PredictionResponse, Error>) -> Void) {
        guard let imageData = image.jpegData(compressionQuality: 0.8) else {
            completion(.failure(NSError(domain: "", code: -1, userInfo: [NSLocalizedDescriptionKey: "Invalid image"])))
            return
        }

        AF.upload(
            multipartFormData: { multipartFormData in
                multipartFormData.append(imageData, withName: "file", fileName: "image.jpg", mimeType: "image/jpeg")
            },
            to: "\(baseURL)/predict"
        )
        .validate()
        .responseDecodable(of: PredictionResponse.self) { response in
            switch response.result {
            case .success(let result):
                completion(.success(result))
            case .failure(let error):
                completion(.failure(error))
            }
        }
    }

    // Health Check
    func checkHealth(completion: @escaping (Bool) -> Void) {
        AF.request("\(baseURL)/health")
            .validate()
            .responseDecodable(of: HealthResponse.self) { response in
                if case .success(let health) = response.result {
                    completion(health.status == "healthy")
                } else {
                    completion(false)
                }
            }
    }
}

// Usage in ViewController
class ClassifierViewController: UIViewController {

    func classifySelectedImage(_ image: UIImage) {
        // Show loading indicator
        showLoadingIndicator()

        CatDogAPIService.shared.predictImage(image: image) { [weak self] result in
            // Hide loading indicator
            self?.hideLoadingIndicator()

            switch result {
            case .success(let prediction):
                // Update UI with results
                self?.displayPrediction(prediction)

            case .failure(let error):
                // Show error alert
                self?.showError(error.localizedDescription)
            }
        }
    }

    func displayPrediction(_ prediction: PredictionResponse) {
        let emoji = prediction.prediction == "Cat" ? "üê±" : "üêï"
        resultLabel.text = "\(emoji) \(prediction.prediction)"
        confidenceLabel.text = String(format: "%.1f%% confident", prediction.confidence_percentage)

        // Update progress bar
        confidenceProgressBar.setProgress(Float(prediction.confidence_percentage / 100), animated: true)
    }
}
```

### Node.js (Express Backend)

Integrate into your Node.js backend.

```javascript
const express = require("express");
const multer = require("multer");
const FormData = require("form-data");
const axios = require("axios");
const fs = require("fs");

const app = express();
const upload = multer({ dest: "uploads/" });

const API_URL = "http://localhost:8000";

// Proxy endpoint for image classification
app.post("/api/classify", upload.single("image"), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: "No image uploaded" });
    }

    // Create form data
    const formData = new FormData();
    formData.append("file", fs.createReadStream(req.file.path));

    // Send to classification API
    const response = await axios.post(`${API_URL}/predict`, formData, {
      headers: formData.getHeaders(),
    });

    // Clean up uploaded file
    fs.unlinkSync(req.file.path);

    // Return result
    res.json(response.data);
  } catch (error) {
    console.error("Classification error:", error);
    res.status(500).json({ error: "Classification failed" });
  }
});

// Health check endpoint
app.get("/api/health", async (req, res) => {
  try {
    const response = await axios.get(`${API_URL}/health`);
    res.json(response.data);
  } catch (error) {
    res.status(503).json({ status: "unhealthy" });
  }
});

app.listen(3000, () => {
  console.log("Server running on http://localhost:3000");
});
```

---

### High-Level Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  User Opens App ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Load/Download CNN Model ‚îÇ  (111 MB, cached)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Upload Image    ‚îÇ  (JPG/PNG)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Preprocess Image        ‚îÇ
‚îÇ ‚Ä¢ Convert to RGB        ‚îÇ
‚îÇ ‚Ä¢ Resize to 128√ó128     ‚îÇ
‚îÇ ‚Ä¢ Normalize (0-1)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ CNN Prediction          ‚îÇ
‚îÇ ‚Ä¢ Forward pass          ‚îÇ
‚îÇ ‚Ä¢ Get probability       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Classify Result         ‚îÇ
‚îÇ ‚Ä¢ Score > 0.5 = Dog üêï  ‚îÇ
‚îÇ ‚Ä¢ Score ‚â§ 0.5 = Cat üê±  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Display Results         ‚îÇ
‚îÇ ‚Ä¢ Animated card         ‚îÇ
‚îÇ ‚Ä¢ Confidence meter      ‚îÇ
‚îÇ ‚Ä¢ Detailed metrics      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Detailed Component Workflow

#### 1. **Model Loading** (`load_trained_model()`)

- Checks if model file exists locally
- Downloads from Google Drive if missing
- Loads Keras model into memory
- Caches using `@st.cache_resource` for performance

#### 2. **Image Preprocessing** (`preprocess_image()`)

```python
Input: PIL Image (any size)
  ‚Üì
Convert to RGB
  ‚Üì
Resize to 128√ó128 pixels
  ‚Üì
Normalize: pixel_values / 255.0
  ‚Üì
Add batch dimension: (1, 128, 128, 3)
  ‚Üì
Output: NumPy array ready for model
```

#### 3. **Prediction** (`predict_image()`)

```python
Input: Model + PIL Image
  ‚Üì
Preprocess image
  ‚Üì
Run model.predict()
  ‚Üì
Get probability score (0.0 to 1.0)
  ‚Üì
Classify: if score > 0.5 ‚Üí Dog, else ‚Üí Cat
  ‚Üì
Calculate confidence: max(score, 1-score)
  ‚Üì
Output: {prediction, label, confidence, emoji, card_class}
```

#### 4. **UI Rendering**

- Side-by-side columns: Image preview | Prediction card
- Animated gradient cards (orange for cat, blue for dog)
- Real-time confidence visualization
- Expandable technical details

## üèóÔ∏è Model Architecture

### Training Overview

- **Dataset:** 25,000 labeled images of cats and dogs
- **Training Accuracy:** ~92%
- **Framework:** TensorFlow/Keras
- **Architecture:** Deep Convolutional Neural Network (CNN)
- **Input Shape:** 128√ó128√ó3 (RGB images)
- **Output:** Single probability (binary classification)

### CNN Architecture Highlights

```
Input (128x128x3)
    ‚Üì
Conv2D + ReLU + BatchNorm
    ‚Üì
MaxPooling2D
    ‚Üì
Conv2D + ReLU + BatchNorm
    ‚Üì
MaxPooling2D
    ‚Üì
Dropout (regularization)
    ‚Üì
Flatten
    ‚Üì
Dense + ReLU
    ‚Üì
Dropout
    ‚Üì
Dense + Sigmoid (output)
    ‚Üì
Probability (0.0 - 1.0)
  ‚Ä¢ Score > 0.5 = Dog üêï
  ‚Ä¢ Score ‚â§ 0.5 = Cat üê±
```

### Key Features

- **Batch Normalization** - Stable and faster training
- **Dropout Layers** - Prevents overfitting
- **MaxPooling** - Reduces spatial dimensions
- **ReLU Activation** - Non-linear transformations
- **Sigmoid Output** - Binary probability

### Model File Details

- **Format:** Keras (.keras)
- **Size:** 111 MB
- **Download:** Automatic from Google Drive
- **Google Drive ID:** `1NUmowM-IX9yRhsNad1G42042YAEzYVig`
- **Storage:** Cached locally after first download

### Training Notebook

The complete training process is available in:

- **File:** `Dogs_vs_Cats_Image_Classification_CNN.ipynb`
- **Includes:** Data preprocessing, augmentation, training, evaluation

---

## üîÑ Project Workflow

### High-Level Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    USER INTERACTION                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                               ‚îÇ
         ‚ñº                               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Web Interface  ‚îÇ           ‚îÇ   REST API      ‚îÇ
‚îÇ   (Streamlit)   ‚îÇ           ‚îÇ   (FastAPI)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                               ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ   Model Loading/Caching       ‚îÇ
         ‚îÇ   ‚Ä¢ Check if model exists     ‚îÇ
         ‚îÇ   ‚Ä¢ Download from GDrive      ‚îÇ
         ‚îÇ   ‚Ä¢ Load into memory          ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ   Image Preprocessing         ‚îÇ
         ‚îÇ   ‚Ä¢ Convert to RGB            ‚îÇ
         ‚îÇ   ‚Ä¢ Resize to 128√ó128         ‚îÇ
         ‚îÇ   ‚Ä¢ Normalize (0-1)           ‚îÇ
         ‚îÇ   ‚Ä¢ Add batch dimension       ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ   CNN Prediction              ‚îÇ
         ‚îÇ   ‚Ä¢ Forward pass              ‚îÇ
         ‚îÇ   ‚Ä¢ Get probability (0-1)     ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ   Result Classification       ‚îÇ
         ‚îÇ   ‚Ä¢ Score > 0.5 = Dog üêï      ‚îÇ
         ‚îÇ   ‚Ä¢ Score ‚â§ 0.5 = Cat üê±      ‚îÇ
         ‚îÇ   ‚Ä¢ Calculate confidence      ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ   Return Results              ‚îÇ
         ‚îÇ   ‚Ä¢ Web: Visual display       ‚îÇ
         ‚îÇ   ‚Ä¢ API: JSON response        ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Detailed Component Workflow

#### 1. **Model Loading** (`load_trained_model()`)

```python
1. Check if model file exists locally
   ‚îú‚îÄ YES ‚Üí Load model from disk
   ‚îî‚îÄ NO  ‚Üí Download from Google Drive
            ‚îú‚îÄ Use gdown library
            ‚îú‚îÄ Save to local disk
            ‚îî‚îÄ Load model into memory

2. Cache model using @st.cache_resource (Streamlit)
   or global variable (FastAPI)

3. Return loaded model
```

#### 2. **Image Preprocessing** (`preprocess_image()`)

```python
Input: PIL Image (any size, any mode)
  ‚Üì
Step 1: Convert to RGB
  ‚Ä¢ Handles: RGBA, Grayscale, etc.
  ‚Ä¢ Output: RGB mode
  ‚Üì
Step 2: Resize to 128√ó128
  ‚Ä¢ Uses: PIL.Image.resize()
  ‚Ä¢ Interpolation: LANCZOS (high quality)
  ‚Üì
Step 3: Convert to NumPy array
  ‚Ä¢ Shape: (128, 128, 3)
  ‚Üì
Step 4: Normalize pixel values
  ‚Ä¢ Formula: pixel_value / 255.0
  ‚Ä¢ Range: [0.0, 1.0]
  ‚Üì
Step 5: Add batch dimension
  ‚Ä¢ Shape: (1, 128, 128, 3)
  ‚Üì
Output: NumPy array ready for model
```

#### 3. **Prediction Process**

```python
Input: Preprocessed image array
  ‚Üì
CNN Forward Pass
  ‚îú‚îÄ Conv layers extract features
  ‚îú‚îÄ Pooling reduces dimensions
  ‚îú‚îÄ Dropout prevents overfitting
  ‚îî‚îÄ Dense layers classify
  ‚Üì
Output: Probability score (0.0 to 1.0)
  ‚Üì
Classification Logic:
  if score > 0.5:
      prediction = "Dog"
      confidence = score * 100
  else:
      prediction = "Cat"
      confidence = (1 - score) * 100
  ‚Üì
Return: {
    "prediction": "Cat" or "Dog",
    "confidence": 0-100%,
    "raw_score": 0.0-1.0,
    "probabilities": {"cat": X%, "dog": Y%}
}
```

---

## üìÅ Project Structure

```
Image-Classification-CNN/
‚îÇ
‚îú‚îÄ‚îÄ üìÑ Core Application Files
‚îÇ   ‚îú‚îÄ‚îÄ streamlit_app.py              # Streamlit web interface (UI for end-users)
‚îÇ   ‚îî‚îÄ‚îÄ api.py                         # FastAPI REST API server (for integrations)
‚îÇ
‚îú‚îÄ‚îÄ üìã Dependencies
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt               # Streamlit app dependencies
‚îÇ   ‚îî‚îÄ‚îÄ requirements-api.txt           # FastAPI dependencies
‚îÇ
‚îú‚îÄ‚îÄ üê≥ Docker & Deployment
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                     # Container image definition
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml             # Multi-container orchestration
‚îÇ
‚îú‚îÄ‚îÄ üß™ Testing & Examples
‚îÇ   ‚îú‚îÄ‚îÄ test_api.py                    # Comprehensive unit tests (pytest)
‚îÇ   ‚îú‚îÄ‚îÄ test_api_quick.py              # Quick API verification script
‚îÇ   ‚îî‚îÄ‚îÄ api_client_example.py          # Python client usage examples
‚îÇ
‚îú‚îÄ‚îÄ üöÄ Convenience Scripts
‚îÇ   ‚îú‚îÄ‚îÄ start_api.ps1                  # Windows PowerShell launcher
‚îÇ   ‚îî‚îÄ‚îÄ start_api.sh                   # Linux/Mac bash launcher
‚îÇ
‚îú‚îÄ‚îÄ ü§ñ Model Files
‚îÇ   ‚îú‚îÄ‚îÄ dogs_vs_cats_production_model.keras  # Trained CNN model (111 MB)
‚îÇ   ‚îî‚îÄ‚îÄ Dogs_vs_Cats_Image_Classification_CNN.ipynb  # Training notebook
‚îÇ
‚îú‚îÄ‚îÄ üìñ Documentation
‚îÇ   ‚îî‚îÄ‚îÄ README.md                      # This comprehensive guide
‚îÇ
‚îî‚îÄ‚îÄ üìÅ __pycache__/                    # Python bytecode cache (auto-generated)
```

### File Descriptions

| File/Directory            | Purpose                                 | When to Use                              |
| ------------------------- | --------------------------------------- | ---------------------------------------- |
| **streamlit_app.py**      | Interactive web UI with visual feedback | End-users, demos, presentations          |
| **api.py**                | RESTful API server                      | App integration, mobile apps, automation |
| **requirements.txt**      | Streamlit dependencies                  | Installing web application               |
| **requirements-api.txt**  | FastAPI dependencies                    | Installing REST API                      |
| **Dockerfile**            | Container image specification           | Docker deployments, cloud hosting        |
| **docker-compose.yml**    | Container orchestration config          | Easy local/production deployment         |
| **test_api.py**           | Comprehensive test suite                | CI/CD pipelines, quality assurance       |
| **test_api_quick.py**     | Rapid API health check                  | Post-deployment verification             |
| **api_client_example.py** | Integration code samples                | Learning API usage patterns              |
| **start_api scripts**     | Platform-specific launchers             | Quick server startup                     |
| **model.keras**           | Trained model weights                   | Auto-downloaded on first run             |
| **Training notebook**     | Model development process               | Understanding architecture, retraining   |

### Dependencies Breakdown

**requirements.txt** (Web App):

```
streamlit>=1.28.0       # Web application framework
tensorflow>=2.13.0      # Deep learning engine
pillow>=10.0.0          # Image processing
numpy>=1.24.0           # Numerical computations
gdown>=4.7.1            # Google Drive downloader
```

**requirements-api.txt** (REST API):

```
fastapi>=0.104.0        # Modern web framework
uvicorn[standard]>=0.24.0  # ASGI server
python-multipart>=0.0.6 # File upload support
tensorflow>=2.13.0      # Deep learning engine
pillow>=10.0.0          # Image processing
numpy>=1.24.0           # Numerical computations
gdown>=4.7.1            # Google Drive downloader
```

**Why Separate Requirements Files?**

| Aspect          | Benefit                                      |
| --------------- | -------------------------------------------- |
| **Size**        | Smaller installations for specific use cases |
| **Conflicts**   | Prevents dependency version conflicts        |
| **Clarity**     | Clear separation of concerns                 |
| **Docker**      | Smaller container images                     |
| **Development** | Install only what you need                   |

---

## üîß Technologies Used

### Core Framework & Languages

- **Python 3.8+** - Primary programming language
- **TensorFlow 2.13+** - Deep learning framework for model training and inference
- **Keras** - High-level neural networks API (part of TensorFlow)

### Web Frameworks

- **Streamlit 1.28+** - Rapid web app development for data science
- **FastAPI 0.104+** - Modern, fast web framework for building APIs
- **Uvicorn** - Lightning-fast ASGI server

### Image Processing & ML

- **NumPy** - Fundamental package for numerical computing
- **Pillow (PIL)** - Python Imaging Library for image manipulation
- **OpenCV** (optional) - Computer vision library for advanced preprocessing

### Development & Testing

- **pytest** - Testing framework
- **black** - Code formatter
- **flake8** - Linter for code quality
- **mypy** - Static type checker

### Deployment & DevOps

- **Docker** - Containerization platform
- **Docker Compose** - Multi-container orchestration
- **Gunicorn** - Production WSGI server
- **Nginx** (recommended) - Reverse proxy and load balancer

### Model Details

- **Architecture**: Convolutional Neural Network (CNN)
- **Input**: 128√ó128√ó3 RGB images
- **Output**: Binary classification (Cat vs Dog)
- **Layers**: Conv2D, MaxPooling2D, Dropout, Dense, BatchNormalization
- **Activation**: ReLU (hidden), Sigmoid (output)
- **Optimizer**: Adam
- **Loss Function**: Binary Crossentropy
- **Metrics**: Accuracy (~92%)
- **Model Size**: 111 MB
- **Training Dataset**: 25,000 labeled images from Kaggle

### Cloud & Hosting Options

Compatible with major cloud platforms:

- **AWS** - EC2, ECS, Lambda, Elastic Beanstalk
- **Google Cloud** - Compute Engine, Cloud Run, App Engine
- **Azure** - Virtual Machines, Container Instances, App Service
- **Heroku** - Easy deployment with buildpacks
- **Railway** - Modern PaaS with automatic deployments
- **Render** - Free tier available for testing
- **DigitalOcean** - App Platform for managed deployments
- **Vercel/Netlify** - Serverless functions (with adaptations)

---

## üîÑ Project Workflow

### Complete Application Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      USER INTERACTION                        ‚îÇ
‚îÇ  ‚Ä¢ Web Browser (Streamlit)  OR  ‚Ä¢ API Client (Any Platform) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                               ‚îÇ
         ‚ñº                               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Streamlit Web UI   ‚îÇ         ‚îÇ   FastAPI Server    ‚îÇ
‚îÇ  ‚Ä¢ File uploader    ‚îÇ         ‚îÇ   ‚Ä¢ RESTful routes  ‚îÇ
‚îÇ  ‚Ä¢ Visual feedback  ‚îÇ         ‚îÇ   ‚Ä¢ JSON responses  ‚îÇ
‚îÇ  ‚Ä¢ Result display   ‚îÇ         ‚îÇ   ‚Ä¢ Batch support   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ                               ‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚ñº
           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ   Model Loading & Caching     ‚îÇ
           ‚îÇ  1. Check if model exists     ‚îÇ
           ‚îÇ  2. Download from GDrive      ‚îÇ
           ‚îÇ  3. Load into memory          ‚îÇ
           ‚îÇ  4. Cache for performance     ‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚ñº
           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ   Image Preprocessing         ‚îÇ
           ‚îÇ  1. Validate file type        ‚îÇ
           ‚îÇ  2. Convert to RGB            ‚îÇ
           ‚îÇ  3. Resize to 128√ó128         ‚îÇ
           ‚îÇ  4. Normalize (0-1 range)     ‚îÇ
           ‚îÇ  5. Add batch dimension       ‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚ñº
           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ   CNN Prediction              ‚îÇ
           ‚îÇ  ‚Ä¢ Convolutional layers       ‚îÇ
           ‚îÇ  ‚Ä¢ Feature extraction         ‚îÇ
           ‚îÇ  ‚Ä¢ Pooling & dropout          ‚îÇ
           ‚îÇ  ‚Ä¢ Dense classification       ‚îÇ
           ‚îÇ  ‚Ä¢ Sigmoid output (0-1)       ‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚ñº
           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ   Result Classification       ‚îÇ
           ‚îÇ  ‚Ä¢ Score > 0.5 = Dog üêï       ‚îÇ
           ‚îÇ  ‚Ä¢ Score ‚â§ 0.5 = Cat üê±       ‚îÇ
           ‚îÇ  ‚Ä¢ Calculate confidence       ‚îÇ
           ‚îÇ  ‚Ä¢ Compute probabilities      ‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                                   ‚îÇ
         ‚ñº                                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Streamlit UI      ‚îÇ            ‚îÇ   API Response     ‚îÇ
‚îÇ  ‚Ä¢ Animated card   ‚îÇ            ‚îÇ   ‚Ä¢ JSON payload   ‚îÇ
‚îÇ  ‚Ä¢ Confidence bar  ‚îÇ            ‚îÇ   ‚Ä¢ Metadata       ‚îÇ
‚îÇ  ‚Ä¢ Emoji display   ‚îÇ            ‚îÇ   ‚Ä¢ Status codes   ‚îÇ
‚îÇ  ‚Ä¢ Expandable info ‚îÇ            ‚îÇ   ‚Ä¢ Error handling ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Detailed Processing Pipeline

#### 1. Model Loading (`load_trained_model()`)

```python
‚îå‚îÄ Check local filesystem
‚îÇ  ‚îú‚îÄ Model exists?
‚îÇ  ‚îÇ  ‚îú‚îÄ YES ‚Üí Load from disk
‚îÇ  ‚îÇ  ‚îî‚îÄ NO  ‚Üí Download from Google Drive
‚îÇ  ‚îÇ           ‚îú‚îÄ Use gdown library
‚îÇ  ‚îÇ           ‚îú‚îÄ Show progress bar
‚îÇ  ‚îÇ           ‚îî‚îÄ Save to local disk
‚îÇ  ‚îÇ
‚îÇ  ‚îú‚îÄ Load model with TensorFlow
‚îÇ  ‚îú‚îÄ Verify model architecture
‚îÇ  ‚îî‚îÄ Cache in memory
‚îÇ
‚îî‚îÄ Return: Loaded Keras model
```

#### 2. Image Preprocessing (`preprocess_image()`)

```python
Input: PIL Image (any size, any format)
  ‚îÇ
  ‚îú‚îÄ Step 1: Mode Conversion
  ‚îÇ   ‚îú‚îÄ Check current mode (RGB, RGBA, L, etc.)
  ‚îÇ   ‚îú‚îÄ Convert to RGB if needed
  ‚îÇ   ‚îî‚îÄ Output: RGB image
  ‚îÇ
  ‚îú‚îÄ Step 2: Resize
  ‚îÇ   ‚îú‚îÄ Target: 128√ó128 pixels
  ‚îÇ   ‚îú‚îÄ Method: LANCZOS (high quality)
  ‚îÇ   ‚îî‚îÄ Output: 128√ó128 RGB image
  ‚îÇ
  ‚îú‚îÄ Step 3: Array Conversion
  ‚îÇ   ‚îú‚îÄ Convert PIL to NumPy array
  ‚îÇ   ‚îî‚îÄ Shape: (128, 128, 3)
  ‚îÇ
  ‚îú‚îÄ Step 4: Normalization
  ‚îÇ   ‚îú‚îÄ Formula: pixel_value / 255.0
  ‚îÇ   ‚îú‚îÄ Range: [0, 255] ‚Üí [0.0, 1.0]
  ‚îÇ   ‚îî‚îÄ Reason: Neural networks prefer normalized inputs
  ‚îÇ
  ‚îú‚îÄ Step 5: Batch Dimension
  ‚îÇ   ‚îú‚îÄ Add dimension for batch processing
  ‚îÇ   ‚îî‚îÄ Shape: (1, 128, 128, 3)
  ‚îÇ
  ‚îî‚îÄ Output: NumPy array ready for model inference
```

#### 3. CNN Prediction Process

```python
Input: Preprocessed image array (1, 128, 128, 3)
  ‚îÇ
  ‚îú‚îÄ Convolutional Layers
  ‚îÇ   ‚îú‚îÄ Extract low-level features (edges, textures)
  ‚îÇ   ‚îú‚îÄ Apply ReLU activation
  ‚îÇ   ‚îî‚îÄ Batch normalization for stability
  ‚îÇ
  ‚îú‚îÄ Pooling Layers
  ‚îÇ   ‚îú‚îÄ Reduce spatial dimensions
  ‚îÇ   ‚îî‚îÄ Retain important features
  ‚îÇ
  ‚îú‚îÄ Dropout Layers
  ‚îÇ   ‚îú‚îÄ Prevent overfitting
  ‚îÇ   ‚îî‚îÄ Random neuron deactivation
  ‚îÇ
  ‚îú‚îÄ Flatten Layer
  ‚îÇ   ‚îî‚îÄ Convert 2D features to 1D vector
  ‚îÇ
  ‚îú‚îÄ Dense Layers
  ‚îÇ   ‚îú‚îÄ High-level feature combination
  ‚îÇ   ‚îî‚îÄ Classification logic
  ‚îÇ
  ‚îú‚îÄ Sigmoid Output
  ‚îÇ   ‚îî‚îÄ Output: Single value [0.0, 1.0]
  ‚îÇ
  ‚îú‚îÄ Classification Logic
  ‚îÇ   ‚îú‚îÄ if score > 0.5:
  ‚îÇ   ‚îÇ   ‚îú‚îÄ prediction = "Dog"
  ‚îÇ   ‚îÇ   ‚îî‚îÄ confidence = score √ó 100
  ‚îÇ   ‚îî‚îÄ else:
  ‚îÇ       ‚îú‚îÄ prediction = "Cat"
  ‚îÇ       ‚îî‚îÄ confidence = (1 - score) √ó 100
  ‚îÇ
  ‚îî‚îÄ Output: {
        "prediction": "Cat" or "Dog",
        "confidence_percentage": 0-100%,
        "raw_score": 0.0-1.0,
        "probabilities": {"cat": X%, "dog": Y%}
      }
```

---

## üêõ Troubleshooting

### Common Issues and Solutions

#### Issue 1: Model Download Fails

**Symptoms:**

```
Error: Failed to download model
ConnectionError: Unable to reach Google Drive
```

**Solutions:**

1. **Check Internet Connection**

   ```powershell
   # Test connectivity
   ping google.com
   ```

2. **Manual Download**

   - Visit: https://drive.google.com/uc?id=1NUmowM-IX9yRhsNad1G42042YAEzYVig
   - Download the file
   - Place in project root as `dogs_vs_cats_production_model.keras`

3. **Firewall/Proxy Issues**

   ```powershell
   # Set proxy (if needed)
   $env:HTTP_PROXY="http://proxy.company.com:8080"
   $env:HTTPS_PROXY="http://proxy.company.com:8080"
   ```

4. **Alternative Download Method**
   ```python
   import gdown
   url = "https://drive.google.com/uc?id=1NUmowM-IX9yRhsNad1G42042YAEzYVig"
   output = "dogs_vs_cats_production_model.keras"
   gdown.download(url, output, quiet=False)
   ```

---

#### Issue 2: Import/Module Errors

**Symptoms:**

```
ModuleNotFoundError: No module named 'streamlit'
ModuleNotFoundError: No module named 'tensorflow'
```

**Solutions:**

1. **Verify Virtual Environment**

   ```powershell
   # Check if venv is activated
   # You should see (venv) in prompt

   # If not activated:
   .\venv\Scripts\Activate.ps1  # Windows
   source venv/bin/activate      # Linux/Mac
   ```

2. **Install Dependencies**

   ```bash
   # For web app
   pip install -r requirements.txt

   # For API
   pip install -r requirements-api.txt

   # Force reinstall
   pip install --force-reinstall -r requirements.txt
   ```

3. **Check Python Version**

   ```bash
   python --version  # Should be 3.8 or higher

   # If multiple Python versions:
   python3.10 -m pip install -r requirements.txt
   ```

4. **Update pip**
   ```bash
   python -m pip install --upgrade pip
   ```

---

#### Issue 3: Port Already in Use

**Symptoms:**

```
Error: Address already in use
OSError: [Errno 98] Address already in use
```

**Solutions:**

1. **Change Port (Streamlit)**

   ```bash
   streamlit run streamlit_app.py --server.port 8502
   ```

2. **Change Port (FastAPI)**

   ```bash
   uvicorn api:app --port 8001
   ```

3. **Find and Kill Process (Windows)**

   ```powershell
   # Find process on port 8000
   netstat -ano | findstr :8000

   # Kill process (replace PID with actual process ID)
   taskkill /PID <PID> /F
   ```

4. **Find and Kill Process (Linux/Mac)**

   ```bash
   # Find process on port 8000
   lsof -i :8000

   # Kill process
   kill -9 <PID>
   ```

---

#### Issue 4: Low Prediction Accuracy

**Symptoms:**

```
Model predicting incorrectly
Confidence seems random
Results don't match visual inspection
```

**Solutions:**

1. **Check Image Quality**

   - Ensure images are clear and well-lit
   - Animal should be the main subject
   - Avoid heavily filtered or obscured images
   - Remove images with multiple animals

2. **Verify Image Format**

   - Use JPG, JPEG, or PNG formats
   - Avoid corrupted or partial images
   - Check file size (not too small)

3. **Test with Known Images**

   ```python
   # Download test images
   import requests

   # Clear cat image
   cat_url = "https://example.com/clear_cat.jpg"
   response = requests.get(cat_url)
   with open("test_cat.jpg", "wb") as f:
       f.write(response.content)
   ```

4. **Model Limitations**
   - Model trained on standard cat/dog images
   - May struggle with:
     - Cartoon/drawn animals
     - Extreme angles or crops
     - Multiple animals in frame
     - Non-standard breeds

---

#### Issue 5: TensorFlow Warnings

**Symptoms:**

```
WARNING:tensorflow:...
Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
```

**Solutions:**

1. **Suppress Warnings (if safe to ignore)**

   ```python
   import os
   os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 0=all, 1=info, 2=warning, 3=error
   ```

2. **Install Optimized TensorFlow**

   ```bash
   # For better CPU performance
   pip install intel-tensorflow
   ```

3. **Use GPU Version (if CUDA available)**
   ```bash
   pip uninstall tensorflow
   pip install tensorflow-gpu
   ```

---

#### Issue 6: Docker Build Fails

**Symptoms:**

```
ERROR: failed to solve: process "/bin/sh -c pip install..." did not complete successfully
```

**Solutions:**

1. **Check Docker Resources**

   - Increase memory allocation in Docker Desktop
   - Increase disk space

2. **Clear Docker Cache**

   ```bash
   docker system prune -a
   docker volume prune
   ```

3. **Build with No Cache**

   ```bash
   docker build --no-cache -t cat-dog-api .
   ```

4. **Check Dockerfile Syntax**
   - Ensure requirements files exist
   - Verify paths are correct
   - Check for typos in commands

---

#### Issue 7: API CORS Errors

**Symptoms:**

```
Access to fetch at 'http://localhost:8000/predict' from origin 'http://localhost:3000' has been blocked by CORS policy
```

**Solutions:**

1. **Check CORS Configuration in api.py**

   ```python
   from fastapi.middleware.cors import CORSMiddleware

   app.add_middleware(
       CORSMiddleware,
       allow_origins=["*"],  # Allow all origins (development only)
       allow_credentials=True,
       allow_methods=["*"],
       allow_headers=["*"],
   )
   ```

2. **Production CORS (specific origins)**

   ```python
   allow_origins=[
       "https://yourdomain.com",
       "http://localhost:3000",  # React dev server
   ]
   ```

3. **Test CORS with cURL**
   ```bash
   curl -H "Origin: http://localhost:3000" \
        -H "Access-Control-Request-Method: POST" \
        -H "Access-Control-Request-Headers: Content-Type" \
        -X OPTIONS \
        http://localhost:8000/predict
   ```

---

#### Issue 8: Memory Errors

**Symptoms:**

```
MemoryError: Unable to allocate array
ResourceExhausted: OOM when allocating tensor
```

**Solutions:**

1. **Reduce Batch Size**

   ```python
   # In batch prediction, process fewer images
   MAX_BATCH_SIZE = 5  # Instead of 10
   ```

2. **Clear Memory Between Predictions**

   ```python
   import gc
   import tensorflow as tf

   # After prediction
   gc.collect()
   tf.keras.backend.clear_session()
   ```

3. **Limit TensorFlow GPU Memory**

   ```python
   import tensorflow as tf

   gpus = tf.config.list_physical_devices('GPU')
   if gpus:
       tf.config.experimental.set_memory_growth(gpus[0], True)
   ```

---

### Getting Help

If you're still experiencing issues:

1. **Check Logs**

   ```bash
   # Streamlit
   streamlit run streamlit_app.py --logger.level=debug

   # FastAPI
   uvicorn api:app --log-level debug

   # Docker
   docker logs <container_name>
   ```

2. **Run Tests**

   ```bash
   pytest test_api.py -v
   python test_api_quick.py
   ```

3. **GitHub Issues**

   - Search existing issues
   - Create new issue with:
     - Error message
     - Python version
     - OS and environment
     - Steps to reproduce

4. **Contact**
   - GitHub: [@fsRakib](https://github.com/fsRakib)
   - Project: [Image-Classification-CNN](https://github.com/fsRakib/Image-Classification-CNN)

---

## ü§ù Contributing

We welcome contributions from the community! Whether you're fixing bugs, adding features, or improving documentation, your help is appreciated.

### How to Contribute

1. **Fork the Repository**

   ```bash
   # Click 'Fork' button on GitHub
   git clone https://github.com/YOUR_USERNAME/Image-Classification-CNN.git
   cd Image-Classification-CNN
   ```

2. **Create a Feature Branch**

   ```bash
   git checkout -b feature/YourAmazingFeature
   ```

3. **Make Your Changes**

   - Write clean, documented code
   - Follow existing code style
   - Add tests if applicable
   - Update documentation

4. **Test Your Changes**

   ```bash
   # Run existing tests
   pytest test_api.py -v

   # Test manually
   python streamlit_app.py  # Test web app
   python api.py             # Test API
   ```

5. **Commit Your Changes**

   ```bash
   git add .
   git commit -m "Add: Your descriptive commit message"
   ```

   **Commit Message Guidelines:**

   - `Add:` New features
   - `Fix:` Bug fixes
   - `Update:` Updates to existing features
   - `Docs:` Documentation changes
   - `Test:` Adding or updating tests

6. **Push to Your Fork**

   ```bash
   git push origin feature/YourAmazingFeature
   ```

7. **Open a Pull Request**
   - Go to the original repository
   - Click "New Pull Request"
   - Describe your changes
   - Link any related issues

### Contribution Ideas

We'd love to see contributions in these areas:

**Feature Enhancements:**

- üéØ Multi-class classification (cats, dogs, other animals)
- üìä Confidence visualization improvements
- üñºÔ∏è Image augmentation preview in UI
- üìà Model performance metrics dashboard
- üîÑ Real-time video classification
- üé® Dark mode for Streamlit app
- üåç Internationalization (i18n) support

**API Improvements:**

- üîê Authentication system (API keys, JWT)
- ‚ö° Rate limiting implementation
- üìù Request logging and analytics
- üöÄ GraphQL API endpoint
- üîó Webhook support for async predictions
- üìä Prometheus metrics endpoint

**Infrastructure:**

- ‚ò∏Ô∏è Kubernetes deployment manifests
- üîÑ CI/CD pipeline (GitHub Actions)
- üì¶ Helm charts for easy deployment
- üê≥ Multi-stage Docker builds
- üß™ Integration tests
- üìè Code coverage reports

**Documentation:**

- üìπ Video tutorials
- üéì Jupyter notebook examples
- üåê API client libraries (JavaScript, Java, Go)
- üì± Mobile app integration guides
- üèóÔ∏è Architecture decision records

**Model Improvements:**

- üß† Fine-tuning for specific breeds
- üîÑ Transfer learning with other models
- üìä Model compression for faster inference
- üéØ Explainable AI (grad-CAM visualizations)

### Code Style Guidelines

- Follow [PEP 8](https://pep8.org/) for Python code
- Use type hints where appropriate
- Write descriptive docstrings
- Keep functions focused and small
- Add comments for complex logic

### Bug Reports

Found a bug? Please open an issue with:

- Clear, descriptive title
- Steps to reproduce
- Expected vs actual behavior
- Python version and OS
- Error messages and stack traces
- Screenshots (if applicable)

### Feature Requests

Have an idea? Open an issue with:

- Description of the feature
- Use case and benefits
- Possible implementation approach
- Mockups or examples (if applicable)

---

## üìù License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for complete details.

### What This Means

‚úÖ **Commercial use** - Use in commercial projects  
‚úÖ **Modification** - Modify and adapt the code  
‚úÖ **Distribution** - Distribute original or modified versions  
‚úÖ **Private use** - Use for private projects

**Conditions:**

- Include the original copyright notice
- Include the license text

**Limitations:**

- No liability or warranty
- No trademark rights

### MIT License Summary

```
MIT License

Copyright (c) 2024 Rakib

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
```

---

## üôè Acknowledgments

This project wouldn't be possible without these amazing resources and communities:

### Dataset

- **Kaggle** - [Dogs vs Cats Dataset](https://www.kaggle.com/c/dogs-vs-cats)
  - 25,000 labeled images for training
  - High-quality, diverse animal photos

### Frameworks & Libraries

- **TensorFlow Team** - Powerful deep learning framework
- **Keras** - High-level neural network API
- **Streamlit** - Rapid web app development
- **FastAPI** - Modern, fast web framework for APIs
- **NumPy** - Fundamental numerical computing
- **Pillow** - Image processing capabilities

### Inspiration & Learning

- **3Blue1Brown** - Neural network visualizations
- **Kaggle Kernels** - Community solutions and approaches
- **Fast.ai** - Deep learning course and best practices
- **TensorFlow Tutorials** - Official guides and examples

### Community

- **Stack Overflow** - Problem-solving and debugging
- **GitHub** - Code hosting and collaboration
- **Reddit r/MachineLearning** - Latest ML research and discussions
- **PyData Community** - Data science best practices

### Special Thanks

- All contributors who have helped improve this project
- Users who provided feedback and reported issues
- The open-source community for continuous innovation

---

## üìß Contact & Support

### Get in Touch

**Primary Contact:**

- üë®‚Äçüíª **GitHub**: [@fsRakib](https://github.com/fsRakib)
- üìÇ **Project Repository**: [Image-Classification-CNN](https://github.com/fsRakib/Image-Classification-CNN)

### Ways to Get Help

1. **üìñ Documentation**

   - Start with this README
   - Check code comments and docstrings
   - Review example files

2. **üêõ Issues**

   - Search [existing issues](https://github.com/fsRakib/Image-Classification-CNN/issues)
   - Create a [new issue](https://github.com/fsRakib/Image-Classification-CNN/issues/new) if needed
   - Include details: OS, Python version, error messages

3. **üí¨ Discussions**

   - General questions
   - Feature ideas
   - Showcase your projects using this API

4. **üöÄ Pull Requests**
   - Bug fixes
   - New features
   - Documentation improvements

### Response Time

- Issues: Typically 24-48 hours
- Pull requests: Reviewed within 3-5 days
- General inquiries: Within a week

### Community Guidelines

When reaching out, please:

- ‚úÖ Be respectful and professional
- ‚úÖ Provide complete information
- ‚úÖ Search for existing answers first
- ‚úÖ Use clear, descriptive titles
- ‚úÖ Include code examples and error messages
- ‚úÖ Specify your environment (OS, Python version)

---

## üìä Performance Metrics

### Model Performance

| Metric                | Value          | Details                        |
| --------------------- | -------------- | ------------------------------ |
| **Training Accuracy** | ~92%           | Validation set performance     |
| **Model Size**        | 111 MB         | Keras .keras format            |
| **Input Resolution**  | 128√ó128 pixels | RGB images, 3 channels         |
| **Parameters**        | ~8.5M          | Total trainable parameters     |
| **Inference Time**    | 100-300ms      | Per image (CPU), faster on GPU |

### API Performance

| Metric                | Value          | Conditions                    |
| --------------------- | -------------- | ----------------------------- |
| **Single Prediction** | ~150-250ms     | Including preprocessing (CPU) |
| **Batch Prediction**  | ~100-150ms/img | Up to 10 images (CPU)         |
| **Throughput**        | ~10-15 req/sec | Single worker, CPU only       |
| **Startup Time**      | ~3-5 seconds   | Model loading time            |
| **Memory Usage**      | ~1.5-2 GB      | With model loaded             |

### Supported Formats

| Format   | Support | Max Size | Notes                          |
| -------- | ------- | -------- | ------------------------------ |
| **JPG**  | ‚úÖ      | 10 MB    | Most common, recommended       |
| **JPEG** | ‚úÖ      | 10 MB    | Same as JPG                    |
| **PNG**  | ‚úÖ      | 10 MB    | Transparency converted to RGB  |
| **WEBP** | ‚ùå      | N/A      | Not currently supported        |
| **GIF**  | ‚ùå      | N/A      | Static only, animation ignored |

### Scaling Recommendations

**For Production:**

- Use **Gunicorn** with multiple workers
- Enable **GPU** acceleration for 5-10x speedup
- Implement **Redis** caching for repeated images
- Use **load balancer** (Nginx) for horizontal scaling
- Deploy on **container orchestration** (Kubernetes)

**Expected Performance with Optimization:**

- **GPU**: ~20-50ms per image
- **Multiple Workers**: 50-100 req/sec
- **Caching**: Sub-10ms for cached results

---

## üéØ Roadmap

### Coming Soon (v2.0)

- [ ] **Multi-animal Classification** - Expand beyond cats and dogs
- [ ] **Model Explainability** - Grad-CAM visualizations
- [ ] **API Authentication** - Secure endpoints with API keys
- [ ] **Batch Upload UI** - Streamlit multi-file support
- [ ] **Model Versioning** - A/B testing different models
- [ ] **Performance Dashboard** - Real-time analytics

### Future Plans

- [ ] **Mobile Apps** - Native iOS and Android apps
- [ ] **Browser Extension** - Right-click image classification
- [ ] **Discord/Slack Bot** - Chat integration
- [ ] **Edge Deployment** - TensorFlow Lite for mobile
- [ ] **Video Classification** - Real-time video analysis
- [ ] **Fine-tuning API** - Custom model training

---

## üåü Star History

If you find this project helpful, please consider giving it a ‚≠ê on GitHub!

[![Star History Chart](https://api.star-history.com/svg?repos=fsRakib/Image-Classification-CNN&type=Date)](https://star-history.com/#fsRakib/Image-Classification-CNN&Date)

---

## üìö Additional Resources

### Learn More

- üìñ [TensorFlow Documentation](https://www.tensorflow.org/guide)
- üìñ [FastAPI Documentation](https://fastapi.tiangolo.com/)
- üìñ [Streamlit Documentation](https://docs.streamlit.io/)
- üìñ [CNN Architecture Explained](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)

### Related Projects

- [Image Classification with PyTorch](https://github.com/pytorch/vision)
- [TensorFlow Model Garden](https://github.com/tensorflow/models)
- [Keras Applications](https://keras.io/api/applications/)

---

<div align="center">

### üéâ Thank You for Using Cat vs Dog AI! üéâ

Made with ‚ù§Ô∏è using **TensorFlow**, **FastAPI**, and **Streamlit**

**Deep Learning** ‚Ä¢ **Computer Vision** ‚Ä¢ **AI**

---

**‚≠ê Star this repo if you found it helpful!**

**üêõ Report issues** ‚Ä¢ **üí° Suggest features** ‚Ä¢ **ü§ù Contribute**

[GitHub](https://github.com/fsRakib/Image-Classification-CNN) | [Issues](https://github.com/fsRakib/Image-Classification-CNN/issues) | [Discussions](https://github.com/fsRakib/Image-Classification-CNN/discussions)

---

_Last Updated: October 2024_

</div>
